{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from scipy.stats import logistic\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_docs(path):\n",
    "    with open(path, 'r') as csv:\n",
    "        next(csv) # skip header\n",
    "        for line in csv:\n",
    "            text, label = line[:-3], int(line[-2])\n",
    "            yield text, label   \n",
    "\n",
    "doc_stream = stream_docs(path='shuffled_movie_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(texto):\n",
    "    import re\n",
    "    REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\')|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\n)\")\n",
    "    REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "    texto = REPLACE_NO_SPACE.sub('', texto.lower())\n",
    "    texto = REPLACE_WITH_SPACE.sub(' ', texto)\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis\n",
    "Las palabras son analizadas mediante un histograma. Todo el dataset es analizado para este estudio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minibatch(doc_stream, size):\n",
    "    docs, y = [], []\n",
    "    for _ in range(size):\n",
    "        text, label = next(doc_stream)\n",
    "        docs.append(text)\n",
    "        y.append(label)\n",
    "    return docs, y\n",
    "\n",
    "def dataAnalysis(doc):\n",
    "    import pandas as pd\n",
    "    \n",
    "    wordsP = list()\n",
    "    countP = list()\n",
    "    \n",
    "    wordsN = list()\n",
    "    countN = list()\n",
    "    \n",
    "    import pyprind\n",
    "    pbar = pyprind.ProgBar(100)\n",
    "    print('Data Analysis -----------------------\\nRead text')\n",
    "    for _ in range(100):\n",
    "        # Getting\n",
    "        x, y = get_minibatch(doc, size=500)\n",
    "        \n",
    "        for xs,ys in zip(x,y):\n",
    "            xs = preprocessing(xs)\n",
    "            \n",
    "            # Positive\n",
    "            if ys==1:\n",
    "                for w in xs.split():\n",
    "                    \n",
    "                    if w in wordsP:\n",
    "                        idx = wordsP.index(w)\n",
    "                        countP[idx] = countP[idx] + 1\n",
    "                    else:\n",
    "                        wordsP.append(w)\n",
    "                        countP.append(1)\n",
    "                \n",
    "            else:\n",
    "                for w in xs.split():\n",
    "                    if w in wordsN:\n",
    "                        idx = wordsN.index(w)\n",
    "                        countN[idx] = countN[idx] + 1\n",
    "                    else:\n",
    "                        wordsN.append(w)\n",
    "                        countN.append(1)\n",
    "                 \n",
    "        # Bar\n",
    "        pbar.update()\n",
    "        \n",
    "        \n",
    "    print('\\nSorting')\n",
    "    positive = sorted(zip(countP,wordsP),reverse=True)\n",
    "    negative = sorted(zip(countN,wordsN),reverse=True)\n",
    "    \n",
    "    positive = pd.DataFrame({'Word' : [w for _,w in positive],\n",
    "                             'Count': [c for c,_ in positive]})\n",
    "    negative = pd.DataFrame({'Word' : [w for _,w in negative],\n",
    "                             'Count': [c for c,_ in negative]})\n",
    "    \n",
    "    return positive,negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#positive,negative = dataAnalysis(doc_stream)\n",
    "\n",
    "# Save\n",
    "#positive.to_csv('positive.csv',index=False)\n",
    "#negative.to_csv('negative.csv',index=False)\n",
    "positive = pd.read_csv('positive.csv')\n",
    "negative = pd.read_csv('negative.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que la cantidad de palabras es muy grande, se delimita una muestra de las 1000 palabras con mayor frecuencia en los grupos de textos de sentimientos positivos y negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select section\n",
    "n = 2000\n",
    "select_positive = positive.loc[:n,:]\n",
    "select_negative = negative.loc[:n,:]\n",
    "\n",
    "select_words_positive = select_positive['Word'].values.tolist()\n",
    "select_words_negative = select_negative['Word'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, analizamos que palabras aparecen m√°s en los textos con sentimientos positivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PosNeg  = list()\n",
    "coefPos = list()\n",
    "\n",
    "Pos_Neg = list()\n",
    "countPN = list()\n",
    "for ip in range( len(select_positive) ):\n",
    "    \n",
    "    w = select_positive.loc[ip,'Word']\n",
    "    \n",
    "    if w in select_words_negative:\n",
    "        count_pos = select_positive.loc[ip,'Count']\n",
    "        count_neg = select_negative.loc[select_negative['Word'] == w,'Count'].values[0]\n",
    "    \n",
    "        PosNeg.append(w)\n",
    "        coefPos.append( count_pos/count_neg )\n",
    "    else:\n",
    "        Pos_Neg.append(w)\n",
    "        countPN.append( select_positive.loc[ip,'Count'] )\n",
    "        \n",
    "interPosNeg = pd.DataFrame({'Word' : PosNeg,'Coefficient': coefPos})\n",
    "excluPosNeg = pd.DataFrame({'Word' : Pos_Neg,'Count': countPN})\n",
    "    \n",
    "interPosNeg = interPosNeg.sort_values('Coefficient',ascending = False).reset_index(drop=True)\n",
    "excluPosNeg = excluPosNeg.sort_values('Count',ascending = False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Razon entre la frecuencia de palabras en textos con sentimientos positivos, con respecto a textos con sentimientos negativos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wonderful</td>\n",
       "      <td>4.803309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>excellent</td>\n",
       "      <td>4.482289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fantastic</td>\n",
       "      <td>4.102837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amazing</td>\n",
       "      <td>3.815109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>powerful</td>\n",
       "      <td>3.485401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>favorite</td>\n",
       "      <td>3.381215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>perfect</td>\n",
       "      <td>3.369902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>brilliant</td>\n",
       "      <td>3.366730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word  Coefficient\n",
       "0  wonderful     4.803309\n",
       "1  excellent     4.482289\n",
       "2  fantastic     4.102837\n",
       "3    amazing     3.815109\n",
       "4   powerful     3.485401\n",
       "5   favorite     3.381215\n",
       "6    perfect     3.369902\n",
       "7  brilliant     3.366730"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interPosNeg.head(n=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Palabras que aparecen solo en los textos con sentimientos positivos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>superb</td>\n",
       "      <td>1092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beautifully</td>\n",
       "      <td>752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>journey</td>\n",
       "      <td>693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subtle</td>\n",
       "      <td>675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>touching</td>\n",
       "      <td>673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>terrific</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>outstanding</td>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bond</td>\n",
       "      <td>626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word  Count\n",
       "0       superb   1092\n",
       "1  beautifully    752\n",
       "2      journey    693\n",
       "3       subtle    675\n",
       "4     touching    673\n",
       "5     terrific    667\n",
       "6  outstanding    642\n",
       "7         bond    626"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excluPosNeg.head(n=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del mismo modo, analizamos que palabras aparecen m√°s en los textos con sentimientos negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NegPos  = list()\n",
    "coefNeg = list()\n",
    "\n",
    "Neg_Pos = list()\n",
    "countNP = list()\n",
    "for ip in range( len(select_negative) ):\n",
    "    \n",
    "    w = select_negative.loc[ip,'Word']\n",
    "    \n",
    "    if w in select_words_positive:\n",
    "        count_pos = select_negative.loc[ip,'Count']\n",
    "        count_neg = select_positive.loc[select_positive['Word'] == w,'Count'].values[0]\n",
    "    \n",
    "        NegPos.append(w)\n",
    "        coefNeg.append( count_pos/count_neg )\n",
    "    else:\n",
    "        Neg_Pos.append(w)\n",
    "        countNP.append(select_negative.loc[ip,'Count'])\n",
    "\n",
    "interNegPos = pd.DataFrame({'Word' : NegPos,'Coefficient': coefNeg})\n",
    "excluNegPos = pd.DataFrame({'Word' : Neg_Pos,'Count': countNP})\n",
    "\n",
    "interNegPos = interNegPos.sort_values('Coefficient',ascending = False).reset_index(drop=True)\n",
    "excluNegPos = excluNegPos.sort_values('Count',ascending = False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Razon entre la frecuencia de palabras en textos con sentimientos negativos, con respecto a textos con sentimientos positivos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>worst</td>\n",
       "      <td>10.975113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>awful</td>\n",
       "      <td>10.247458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>terrible</td>\n",
       "      <td>6.684964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>horrible</td>\n",
       "      <td>6.238806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crap</td>\n",
       "      <td>5.713793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>worse</td>\n",
       "      <td>5.398664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>stupid</td>\n",
       "      <td>5.212727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dull</td>\n",
       "      <td>4.832714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word  Coefficient\n",
       "0     worst    10.975113\n",
       "1     awful    10.247458\n",
       "2  terrible     6.684964\n",
       "3  horrible     6.238806\n",
       "4      crap     5.713793\n",
       "5     worse     5.398664\n",
       "6    stupid     5.212727\n",
       "7      dull     4.832714"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interNegPos.head(n=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Palabras que aparecen solo en los textos con sentimientos negativos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>waste</td>\n",
       "      <td>2590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poorly</td>\n",
       "      <td>1252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lame</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>badly</td>\n",
       "      <td>1053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mess</td>\n",
       "      <td>1017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wasted</td>\n",
       "      <td>1007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dumb</td>\n",
       "      <td>972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fails</td>\n",
       "      <td>940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Word  Count\n",
       "0   waste   2590\n",
       "1  poorly   1252\n",
       "2    lame   1200\n",
       "3   badly   1053\n",
       "4    mess   1017\n",
       "5  wasted   1007\n",
       "6    dumb    972\n",
       "7   fails    940"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excluNegPos.head(n=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features\n",
    "En esta secci√≥n se definen las caracter√≠sticas extradidas de los textos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive lexicon\n",
    "\n",
    "Se busca si existen palabras positivas (definidas por una lista) dentro del texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positiveLexicon(text):\n",
    "    # Good words list\n",
    "    with open('positive-words.txt', 'r') as f:\n",
    "        goodWords = f.read().split('\\n')[:-2]\n",
    "    \n",
    "    good = 0\n",
    "    for w in text.split():\n",
    "        if w in goodWords:\n",
    "            good = good + 1\n",
    "    \n",
    "    return good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative lexicon\n",
    "\n",
    "Se busca si existen palabras negativas (definidas por una lista) dentro del texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negativeLexicon(text):\n",
    "    # Bad words list\n",
    "    with open('negative-words.txt', 'r') as f:\n",
    "        badWords = f.read().split('\\n')[:-2]\n",
    "    \n",
    "    bad = 0\n",
    "    for w in text.split():\n",
    "        if w in badWords:\n",
    "            bad = bad + 1\n",
    "    \n",
    "    return bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does include \"no\"?\n",
    "\n",
    "\n",
    "Verfica si existen palabras 'no','not' dentro del texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doesIncludeNo(text):\n",
    "    nos = ['no','not']\n",
    "    isthereNo = 0\n",
    "    for w in text.split():\n",
    "        if w in nos:\n",
    "            isthereNo = 1\n",
    "            break\n",
    "    \n",
    "    return isthereNo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does include Pronouns (1st and 2nd)? \n",
    "\n",
    "Verifica que exista los pronombres de primer y segundo grado en el texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doesIncludePronouns(text):\n",
    "    pronouns = stopwords.words('english')[:17]\n",
    "    isthere = 0\n",
    "    for w in text.split():\n",
    "        if w in pronouns:\n",
    "            isthere = 1\n",
    "            break\n",
    "    \n",
    "    return isthere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does include \"!\"? \n",
    "\n",
    "Verifica que exista el s√≠mbolo '!' en el texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doesIncludeExclamationMark(text):\n",
    "    return int( '!' in text )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### log(Count words)\n",
    "\n",
    "Calcula el logaritmo de la cantidad de palabras del texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logCountWords(text):\n",
    "    return np.log( len(text.split()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does include More Positives?\n",
    "\n",
    "Verifica que el texto incluya palabras que se encuentran principalmente en textos con sentimientos positivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def morePositives(text):\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv('interPosNeg.csv')\n",
    "    positives = df.loc[:10,'Word'].values.tolist()\n",
    "    \n",
    "    df = pd.read_csv('excluPosNeg.csv')\n",
    "    positives = positives + df.loc[:10,'Word'].values.tolist()\n",
    "    \n",
    "    isthere = 0\n",
    "    for w in text.split():\n",
    "        if w in positives:\n",
    "            isthere = 1\n",
    "            break\n",
    "    \n",
    "    return isthere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does include More Negatives?\n",
    "\n",
    "Verifica que el texto incluya palabras que se encuentran principalmente en textos con sentimientos negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moreNegatives(text):\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv('interNegPos.csv')\n",
    "    negatives = df.loc[:30,'Word'].values.tolist()\n",
    "    \n",
    "    df = pd.read_csv('excluNegPos.csv')\n",
    "    negatives = negatives + df.loc[:2,'Word'].values.tolist()\n",
    "    \n",
    "    isthere = 0\n",
    "    for w in text.split():\n",
    "        if w in negatives:\n",
    "            isthere = 1\n",
    "            break\n",
    "    \n",
    "    return isthere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How much include More Positives?\n",
    "\n",
    "Calcula la cantidad de palabras, que se encuentran principalmente en textos con sentimientos positivos, existen en el texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def howMuchPositives(text,interPosNeg,excluPosNeg):\n",
    "    positives = interPosNeg.loc[:30,'Word'].values.tolist()\n",
    "    positives = positives + excluPosNeg.loc[:2,'Word'].values.tolist()\n",
    "    \n",
    "    count = 0\n",
    "    for w in text.split():\n",
    "        if w in positives:\n",
    "            count = count + 1\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How much include More Negatives?\n",
    "\n",
    "Calcula la cantidad de palabras, que se encuentran principalmente en textos con sentimientos negativos, existen en el texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def howMuchNegatives(text,interNegPos,excluNegPos):\n",
    "    negatives = interNegPos.loc[:30,'Word'].values.tolist()\n",
    "    negatives = negatives + excluNegPos.loc[:2,'Word'].values.tolist()\n",
    "    \n",
    "    count = 0\n",
    "    for w in text.split():\n",
    "        if w in negatives:\n",
    "            count = count + 1\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-6df5bb6da0ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m                    howMuchNegatives          (preprocessing(text),\n\u001b[1;32m     22\u001b[0m                                                       \u001b[0minterNegPos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                                                       excluNegPos)] for text in x_raw ] \n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-6df5bb6da0ee>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     21\u001b[0m                    howMuchNegatives          (preprocessing(text),\n\u001b[1;32m     22\u001b[0m                                                       \u001b[0minterNegPos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                                                       excluNegPos)] for text in x_raw ] \n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-a50dfcf70271>\u001b[0m in \u001b[0;36mmorePositives\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmorePositives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'interPosNeg.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mpositives\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Word'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0mnew_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_currow\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnew_rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    346\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_init_dict\u001b[0;34m(self, data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    430\u001b[0m         \"\"\"\n\u001b[1;32m    431\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mdata_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                 \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "doc_stream = stream_docs(path='shuffled_movie_data.csv')\n",
    "\n",
    "x = list()\n",
    "y = list()\n",
    "for _ in range(50):\n",
    "    # Getting\n",
    "    x_raw, y_raw = get_minibatch(doc_stream, size=1000)\n",
    "    \n",
    "    # Update features\n",
    "    features = [ [ positiveLexicon           (preprocessing(text)),\n",
    "                   negativeLexicon           (preprocessing(text)),\n",
    "                   doesIncludeNo             (preprocessing(text)), \n",
    "                   doesIncludePronouns       (preprocessing(text)),\n",
    "                   doesIncludeExclamationMark(preprocessing(text)),\n",
    "                   logCountWords             (preprocessing(text)),\n",
    "                   morePositives             (preprocessing(text)),\n",
    "                   moreNegatives             (preprocessing(text)),\n",
    "                   howMuchPositives          (preprocessing(text),\n",
    "                                                      interPosNeg,\n",
    "                                                      excluPosNeg),\n",
    "                   howMuchNegatives          (preprocessing(text),\n",
    "                                                      interNegPos,\n",
    "                                                      excluNegPos)] for text in x_raw ] \n",
    "    x = x + features\n",
    "    \n",
    "    # Update out\n",
    "    y = y + y_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StochasticGradientDescent(x_train,y_train):\n",
    "    import random\n",
    "    from scipy.stats import logistic\n",
    "    \n",
    "    # Parameters\n",
    "    eta       = 0.001\n",
    "    err       = 1000\n",
    "    errNorm   = 1000\n",
    "    threshold = 0.00001\n",
    "    \n",
    "    n_samples  = len(x_train   )\n",
    "    n_features = len(x_train[0])\n",
    "    \n",
    "    w = np.zeros(n_features + 1)\n",
    "    \n",
    "    # Train Loop\n",
    "    while (errNorm>threshold):\n",
    "        exErr = err\n",
    "        \n",
    "        # Random selection\n",
    "        n = round(random.uniform(0, n_samples-1))\n",
    "        try:\n",
    "            xs = np.array( x_train[n] + [1] )\n",
    "        except:\n",
    "            print('n: ',n)\n",
    "            print('n_samples: ',n_samples)\n",
    "            \n",
    "        ys = y_train[n]\n",
    "        \n",
    "        # Hypotesis\n",
    "        h = logistic.cdf( np.dot(xs,w) ) \n",
    "        \n",
    "        # Gradient\n",
    "        g = (h - ys)*xs\n",
    "        \n",
    "        # Update\n",
    "        w = w - eta*g\n",
    "        \n",
    "        # Prediction\n",
    "        y_pred = w*xs\n",
    "        \n",
    "        # Error\n",
    "        err = np.sum(np.abs(ys - y_pred))\n",
    "        \n",
    "        # Update error\n",
    "        errNorm = np.abs(exErr - err)/np.abs(err)\n",
    "        \n",
    "    return w\n",
    "\n",
    "def applyModel(x,w):      \n",
    "    \n",
    "    y_pred = list()\n",
    "    for xs in x:\n",
    "        ys =  logistic.cdf( np.dot( np.array(xs + [1]),w ) ) \n",
    "        ys = int( ys > 0.5 )\n",
    "        \n",
    "        y_pred.append(ys)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=8) \n",
    "accuracy = list()\n",
    "\n",
    "for train, test in kf.split(x):    \n",
    "    # Select\n",
    "    x_train = [ x[i] for i in train ]\n",
    "    y_train = [ y[i] for i in train ]\n",
    "    \n",
    "    x_test = [ x[i] for i in test ]\n",
    "    y_test = [ y[i] for i in test ]\n",
    "    \n",
    "    # Run train\n",
    "    w = StochasticGradientDescent(x_train, y_train)\n",
    "    \n",
    "    # Run test\n",
    "    y_pred = applyModel(x_test,w)\n",
    "    \n",
    "    # Accuracy\n",
    "    acc = 0\n",
    "    for real,pred in zip(y_pred,y_test):\n",
    "        acc = acc + int( real == pred )\n",
    "    \n",
    "    accuracy.append( acc*100/len(test) )\n",
    "    \n",
    "    # Bar\n",
    "    pbar.update()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
